{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GMM \n",
    "from featureextraction import extract_features\n",
    "#from speakerfeatures import extract_features\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source      = \"/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/trng_data/\"  \n",
    "test_data_folder   = \"/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/test_data/\"  \n",
    "dest        = \"/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/models/\"\n",
    "\n",
    "#train_file  = \"/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/trngdata.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file_paths = open(train_file,'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker:-> calamity-20071011-poe Data points =  (2711, 40)\n",
      "speaker:-> chocoholic-20070524 Data points =  (2443, 40)\n",
      "speaker:-> chocoholic-20070612-eti33 Data points =  (2775, 40)\n",
      "speaker:-> chocoholic-20080420-pos Data points =  (3499, 40)\n",
      "speaker:-> cloudmountain-20080420-eti Data points =  (1910, 40)\n",
      "speaker:-> cloudmountain-20080420-yos Data points =  (4613, 40)\n",
      "speaker:-> crhylove-10252006 Data points =  (2437, 40)\n",
      "speaker:-> delibab-20071007-poe Data points =  (2809, 40)\n",
      "speaker:-> delibab-20071012 Data points =  (3150, 40)\n",
      "speaker:-> delibab-20071019-poe Data points =  (3202, 40)\n",
      "speaker:-> delibab-20071020 Data points =  (3442, 40)\n",
      "speaker:-> delibab-20071025-poe Data points =  (3915, 40)\n",
      "speaker:-> ductapeguy-20070308b Data points =  (1323, 40)\n",
      "speaker:-> ductapeguy-20070619-com Data points =  (3007, 40)\n",
      "speaker:-> ductapeguy-20080423-pri Data points =  (3227, 40)\n",
      "speaker:-> ductapeguy-20080423-sto Data points =  (3906, 40)\n",
      "speaker:-> gesine-20080421-rid Data points =  (4184, 40)\n",
      "speaker:-> granthulbert-ar-01032007 Data points =  (2777, 40)\n",
      "speaker:-> hugh-20070606-bul Data points =  (3373, 40)\n",
      "speaker:-> jimmowatt-20070308-hoe Data points =  (3087, 40)\n",
      "speaker:-> kayray-20070425-per04 Data points =  (2763, 40)\n",
      "speaker:-> kmaclean-20071108-poe Data points =  (3921, 40)\n",
      "speaker:-> knotyouraveragejo-20070620-sci Data points =  (2867, 40)\n",
      "speaker:-> leonMire-20080526-lev Data points =  (4107, 40)\n",
      "speaker:-> librivoxMP3-20070530-MOB Data points =  (3097, 40)\n",
      "speaker:-> mojomove411-20071007-poe Data points =  (3774, 40)\n",
      "speaker:-> mwalma-20080112 Data points =  (2894, 40)\n",
      "speaker:-> nollidj-20081101-ar Data points =  (2785, 40)\n",
      "speaker:-> peterwhy-20080503-win Data points =  (3939, 40)\n",
      "speaker:-> Raeubertochter-20090911 Data points =  (1633, 40)\n",
      "speaker:-> sil-20090322 Data points =  (2513, 40)\n",
      "speaker:-> starlite-20070605-che Data points =  (3293, 40)\n",
      "speaker:-> tis-20080416-tou Data points =  (3417, 40)\n",
      "speaker:-> tjm1983-20071129 Data points =  (3616, 40)\n",
      "speaker:-> ttm-20071007 Data points =  (2946, 40)\n",
      "speaker:-> ttm-200710072 Data points =  (2946, 40)\n",
      "speaker:-> ttm-200710073 Data points =  (2946, 40)\n"
     ]
    }
   ],
   "source": [
    "features = np.asarray(())\n",
    "\n",
    "for dirs in os.listdir(source):\n",
    "    if dirs == '.DS_Store':\n",
    "        continue\n",
    "    #print(dirs)\n",
    "    dirpath = source+dirs\n",
    "    #print(dirpath)\n",
    "    count=0\n",
    "    for audiofiles in os.listdir(dirpath+'/wav'):\n",
    "\n",
    "        if audiofiles == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        count = count + 1\n",
    "        #print(count,audiofiles)\n",
    "        \n",
    "        \n",
    "        sr,audio = read(dirpath+'/wav'+'/'+audiofiles)\n",
    "\n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "        \n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "        #print(audiofiles)\n",
    "        #print(features.shape)\n",
    "        if count ==5:\n",
    "            \n",
    "            #print(\"Creating GMM \")\n",
    "            gmm = GMM(n_components = 16, n_iter = 200, covariance_type='diag',n_init = 3)\n",
    "            gmm.fit(features)\n",
    "            #print(type(features))\n",
    "            #print(features.shape)\n",
    "            # dumping the trained gaussian model\n",
    "            \n",
    "            picklefile = str(dest.strip()+dirs.strip()+ \".gmm\")\n",
    "            #print(picklefile)\n",
    "            cPickle.dump(gmm,open(picklefile,'wb'))\n",
    "            \n",
    "            print ('speaker:->',dirs,\"Data points = \",features.shape)\n",
    "\n",
    "            count=0\n",
    "            features = np.asarray(())\n",
    "            break\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/models/\"\n",
    "\n",
    "gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "              os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "#print(gmm_files,len(gmm_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models    = [cPickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "spk_list   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname in gmm_files]\n",
    "\n",
    "#print(spk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as0010.wav is detected as -  calamity-20071011-poe\n",
      "as0011.wav is detected as -  calamity-20071011-poe\n",
      "as0012.wav is detected as -  calamity-20071011-poe\n",
      "as0013.wav is detected as -  calamity-20071011-poe\n"
     ]
    }
   ],
   "source": [
    "# Code for Identifying an audio \n",
    "test_dir = r'/Users/jm186072/Documents/DataScience/Speaker-Identification-Python/test1/'\n",
    "total_sample = 0\n",
    "for test_audio_file in os.listdir(test_dir):\n",
    "    \n",
    "    if test_audio_file == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    total_sample += 1.0\n",
    "    \n",
    "    sr,audio = read(test_dir+test_audio_file)\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        gmm    = models[i]  #checking with each model one by one\n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    \n",
    "    print (test_audio_file,\"is detected as - \", spk_list[winner])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Audio Files Processed =  1362 Incorrectly Identified =  192\n",
      "Identification Accuracy --> 85.90308370044053\n"
     ]
    }
   ],
   "source": [
    "total_sample = 0\n",
    "error = 0\n",
    "\n",
    "for speakers in os.listdir(test_data_folder):\n",
    "    if speakers == '.DS_Store':\n",
    "        continue\n",
    "    #print(speakers)\n",
    "    for audio_file in os.listdir(test_data_folder+speakers+'/wav'):\n",
    "        if audio_file == '.DS_Store':\n",
    "            continue\n",
    "        #print('\\t',audio_file)\n",
    "        total_sample += 1 \n",
    "        sr,audio = read(test_data_folder+speakers+'/wav/'+audio_file)\n",
    "        vector = extract_features(audio,sr)\n",
    "        \n",
    "        log_likelihood = np.zeros(len(models))\n",
    "        \n",
    "                    \n",
    "        for i in range(len(models)):\n",
    "            gmm    = models[i]  #checking with each model one by one\n",
    "            scores = np.array(gmm.score(vector))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        #print (\"\\tdetected as - \", speakers[winner])\n",
    "        #print(winner)\n",
    "        if spk_list[winner] != speakers:\n",
    "            error += 1\n",
    "            \n",
    "print ('Total Audio Files Processed = ',total_sample,'Incorrectly Identified = ' , error )\n",
    "print('Identification Accuracy -->',((total_sample - error) / total_sample) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
